{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKOnawA9iL3j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') \n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':384,\n",
        "    'EPOCHS':50,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'SEED':42\n",
        "}\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_img_list = glob.glob('/content/drive/MyDrive/data/dacon/도배하자/open/train/*/*')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/dacon/도배하자/open/test.csv')\n",
        "\n",
        "data = pd.DataFrame(columns=['img_path', 'label'])\n",
        "data['img_path'] = all_img_list\n",
        "data['label'] = data['img_path'].apply(lambda x : str(x).split('/')[-2])"
      ],
      "metadata": {
        "id": "0SxL02bJiRce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, _, _ = train_test_split(data, data['label'], test_size=0.4, stratify=data['label'], random_state=CFG['SEED'])"
      ],
      "metadata": {
        "id": "y-HwzpWqiXqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "train_data['label'] = encoder.fit_transform(train_data['label'])\n",
        "val_data['label'] = encoder.transform(val_data['label'])"
      ],
      "metadata": {
        "id": "jlf0enLBit8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transform = True):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transform = transform\n",
        "        \n",
        "        if self.transform == True:\n",
        "            self.transform = A.Compose([                           \n",
        "                                A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                                A.VerticalFlip(p = 0.5),\n",
        "                                A.RandomBrightness(limit=0.2, always_apply=False, p=0.5),\n",
        "                                A.CLAHE(clip_limit=5.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
        "                                A.Cutout(num_holes=8, max_h_size=20, max_w_size=20, p=0.5),\n",
        "                                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                                ToTensorV2()\n",
        "                                ])\n",
        "\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                                        A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                                        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                                        ToTensorV2()\n",
        "                                        ])\n",
        "            \n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "        \n",
        "        image = cv2.imread(img_path)\n",
        "        image = self.transform(image = image)['image']\n",
        "        \n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ],
      "metadata": {
        "id": "41Ac3Y8vivTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutmix_data(img, target_a, alpha = 1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = img.size()[0]\n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "\n",
        "    shuffled_data = img[index]\n",
        "    target_b = target_a[index]\n",
        "    \n",
        "    image_h, image_w = img.shape[2:]\n",
        "\n",
        "    cx = np.random.uniform(0, image_w)\n",
        "    cy = np.random.uniform(0, image_h)\n",
        "    w = image_w * np.sqrt(1 - lam)\n",
        "    h = image_h * np.sqrt(1 - lam)\n",
        "    x0 = int(np.round(max(cx - w / 2, 0)))\n",
        "    x1 = int(np.round(min(cx + w / 2, image_w)))\n",
        "    y0 = int(np.round(max(cy - h / 2, 0)))\n",
        "    y1 = int(np.round(min(cy + h / 2, image_h)))\n",
        "\n",
        "    img[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n",
        "\n",
        "    return img, target_a, target_b, lam\n",
        "\n",
        "def cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "2wQPzDVx3Vw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Label Smoothing + Focal Loss"
      ],
      "metadata": {
        "id": "3I2Zqd26Gp-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "\n",
        "    def forward(self, y, targets, smoothing=0.1):\n",
        "        confidence = 1. - smoothing\n",
        "        log_probs = F.log_softmax(y, dim=-1) \n",
        "        true_probs = torch.zeros_like(log_probs)\n",
        "        true_probs.fill_(smoothing / (y.shape[1] - 1))\n",
        "        true_probs.scatter_(1, targets.data.unsqueeze(1), confidence) \n",
        "        return torch.mean(torch.sum(true_probs * -log_probs, dim=-1))\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        F_loss = self.alpha * (1-pt) ** self.gamma * ce_loss\n",
        "        return torch.mean(F_loss)\n",
        "\n",
        "class LabelSmoothingFocalLoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, alpha=0.25):\n",
        "        super(LabelSmoothingFocalLoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.alpha = alpha\n",
        "        self.cross_entropy = LabelSmoothingCrossEntropy()\n",
        "        self.focal_loss = FocalLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.cross_entropy(inputs, targets)\n",
        "        fl_loss = self.focal_loss(inputs, targets)\n",
        "        loss = (1 - self.alpha) * ce_loss + self.alpha * fl_loss # \n",
        "        return loss"
      ],
      "metadata": {
        "id": "cR2TwRt6iy6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_data['img_path'].values, train_data['label'].values, transform = True)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=6, pin_memory=True, drop_last=True)\n",
        "\n",
        "val_dataset = CustomDataset(val_data['img_path'].values, val_data['label'].values, transform = False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=6, pin_memory=True, drop_last=False)"
      ],
      "metadata": {
        "id": "PseM9LqJi0es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Swin_B(nn.Module):\n",
        "    def __init__(self, num_class=len(encoder.classes_)):\n",
        "        super().__init__()\n",
        "        self.backbone = models.swin_b(pretrained=True)\n",
        "        self.classifier = nn.Linear(1000, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.classifier(x)\n",
        "        return x                                    "
      ],
      "metadata": {
        "id": "ojv17AeOi2KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False, save_best_only=True):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.save_best_only = save_best_only\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.save_best_only:\n",
        "            if val_loss < self.val_loss_min:\n",
        "                if self.verbose:\n",
        "                    print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "                torch.save(model.state_dict(), self.path)\n",
        "                self.val_loss_min = val_loss\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(f'Validation loss decreased. Saving model ...')\n",
        "            torch.save(model.state_dict(), self.path)\n"
      ],
      "metadata": {
        "id": "sv5JOnFJi90I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    model.to(device)\n",
        "    criterion = LabelSmoothingFocalLoss().to(device)\n",
        "\n",
        "    early_stopping = EarlyStopping(patience = 5, verbose = True)\n",
        "\n",
        "    best_val_loss = float('inf')    \n",
        "    best_state_dict = None\n",
        "    mean_score = 0\n",
        "\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            \n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            imgs, targets_a, targets_b, lam = cutmix_data(imgs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(imgs)\n",
        "            \n",
        "            loss = cutmix_criterion(criterion, output, targets_a, targets_b, lam)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss.append(loss.item())\n",
        "        \n",
        "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_score)\n",
        "            \n",
        "        if _val_loss < best_val_loss:\n",
        "          best_val_loss = _val_loss\n",
        "          best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        early_stopping(_val_loss, model)\n",
        "        \n",
        "        mean_score += _val_score\n",
        "  \n",
        "        if early_stopping.early_stop:\n",
        "          print('Early Stopping')\n",
        "          break\n",
        "\n",
        "    model.load_state_dict(best_state_dict)\n",
        "    return model, mean_score // epoch"
      ],
      "metadata": {
        "id": "CxnFZnBmi_OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    preds = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            true_labels += labels.detach().cpu().numpy().tolist()\n",
        "\n",
        "    score = f1_score(true_labels, preds, average='weighted')\n",
        "    return (np.mean(val_loss), score)"
      ],
      "metadata": {
        "id": "WOQkG2lvjTol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_decoder(preds):\n",
        "    label_to_hangul = {\n",
        "    0: '가구수정',\n",
        "    1: '걸레받이수정',\n",
        "    2: '곰팡이',\n",
        "    3: '꼬임',\n",
        "    4: '녹오염',\n",
        "    5: '들뜸',\n",
        "    6: '면불량',\n",
        "    7: '몰딩수정',\n",
        "    8: '반점',\n",
        "    9: '석고수정',\n",
        "    10: '오염',\n",
        "    11: '오타공',\n",
        "    12: '울음',\n",
        "    13: '이음부불량',\n",
        "    14: '창틀,문틀수정',\n",
        "    15: '터짐',\n",
        "    16: '틈새과다',\n",
        "    17: '피스',\n",
        "    18: '훼손'\n",
        "    }\n",
        "    return [label_to_hangul[pred] for pred in preds]"
      ],
      "metadata": {
        "id": "2yq4l-Oxjvcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Swin_B()\n",
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr = 3e-5)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 50, eta_min = 0.01)\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
      ],
      "metadata": {
        "id": "ThTbJiaauhvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/data/dacon/도배하자/open/test.csv')\n",
        "submit = pd.read_csv('/content/drive/MyDrive/data/dacon/도배하자/open/sample_submission.csv')\n",
        "\n",
        "test_dataset = CustomDataset(test['img_path'].values, None, transform = False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=6)"
      ],
      "metadata": {
        "id": "NPgrVqruABwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    preds_proba = []\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(iter(test_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            \n",
        "            pred = model(imgs)\n",
        "            \n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            preds_proba += F.softmax(pred, dim=1).detach().cpu().numpy().tolist()\n",
        "            \n",
        "    preds = label_decoder(preds)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "Qs7YrpSHAHHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = inference(infer_model, test_loader, device)"
      ],
      "metadata": {
        "id": "LllcT923R69m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['label'] = preds\n",
        "submit.to_csv('./cutmix_labelsmoothFocal_vit_b_384.csv', encoding = 'utf-8', index=False)"
      ],
      "metadata": {
        "id": "4nTG5Fz8AQRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
